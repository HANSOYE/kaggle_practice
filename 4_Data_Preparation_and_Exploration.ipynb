{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4_Data Preparation and Exploration\n",
    "## Porto Seguro’s Safe Driver Prediction\n",
    "# Introduction\n",
    "\n",
    "노트북은 다음과 같은 주요 섹션으로 구성됩니다.\n",
    "\n",
    "1. Visual inspection of your data\n",
    "2. Defining the metadata\n",
    "3. Descriptive statistics\n",
    "4. Handling imbalanced classes\n",
    "5. Data quality checks\n",
    "6. Exploratory data visualization\n",
    "7. Feature engineering\n",
    "8. Feature selection\n",
    "9. Feature scaling\n",
    "\n",
    "# Loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T09:49:03.04969Z",
     "iopub.status.busy": "2022-02-13T09:49:03.048757Z",
     "iopub.status.idle": "2022-02-13T09:49:04.508139Z",
     "shell.execute_reply": "2022-02-13T09:49:04.507469Z",
     "shell.execute_reply.started": "2022-02-13T09:49:03.049632Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.impute import SimpleImputer \n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T09:49:04.509866Z",
     "iopub.status.busy": "2022-02-13T09:49:04.509513Z",
     "iopub.status.idle": "2022-02-13T09:49:15.266079Z",
     "shell.execute_reply": "2022-02-13T09:49:15.265013Z",
     "shell.execute_reply.started": "2022-02-13T09:49:04.509838Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/porto-seguro-safe-driver-prediction/train.csv')\n",
    "test = pd.read_csv('/kaggle/input/porto-seguro-safe-driver-prediction/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data at first sight\n",
    "\n",
    "데이터에 대한 정보들(밑의 head와 tail에서 볼 수 있음):\n",
    "\n",
    "- 비슷한 그룹인 Feature들은 비슷한 이름을 가지고 있다 (예를 들어, ind, reg, car, calc).\n",
    "- **bin** 을 가진 Feature는 **Binary feature**임을 나타내고, **cat** 를 가진 Feature는 **Categorical feature**임을 나타낸다.\n",
    "- 이외의 Feature들은 **Continious** 혹은 **Ordinal feature** 이다.\n",
    "- 값이 -1 인 관측치는 **결측값(NaN)**을 의미한다.\n",
    "- **Target** 컬럼은 Policy holder(보험 계약자=보험료를 납입할 의무를 가진 사람)에게 청구 적용 여부(Y/N)를 나타낸다.\n",
    "\n",
    "### train 데이터의 전체적인 모습을 확인하기 위하여 앞부분(head)과 뒷부분(tail)을 먼저 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T09:49:15.267875Z",
     "iopub.status.busy": "2022-02-13T09:49:15.26754Z",
     "iopub.status.idle": "2022-02-13T09:49:15.316171Z",
     "shell.execute_reply": "2022-02-13T09:49:15.315317Z",
     "shell.execute_reply.started": "2022-02-13T09:49:15.267833Z"
    }
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T09:49:15.318933Z",
     "iopub.status.busy": "2022-02-13T09:49:15.318692Z",
     "iopub.status.idle": "2022-02-13T09:49:15.358528Z",
     "shell.execute_reply": "2022-02-13T09:49:15.357602Z",
     "shell.execute_reply.started": "2022-02-13T09:49:15.318904Z"
    }
   },
   "outputs": [],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 추후에 14개의 **Categorial variables**를 더미화 시킬 것이다.\n",
    "- ex) ps_ind_02_cat(04, 05), ps_car_01_cat(01~11) : 총14개\n",
    "- 접미사로 **bin**이 붙은 **variables**는 이미 0과 1로 구성되어 있으므로 따로 더미화시킬 필요가 없다.(Binary feature)\n",
    "\n",
    "### 밑에서는 train 데이터의 행과 열 수를 살펴보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T09:49:15.360637Z",
     "iopub.status.busy": "2022-02-13T09:49:15.359921Z",
     "iopub.status.idle": "2022-02-13T09:49:15.367719Z",
     "shell.execute_reply": "2022-02-13T09:49:15.366805Z",
     "shell.execute_reply.started": "2022-02-13T09:49:15.360587Z"
    }
   },
   "outputs": [],
   "source": [
    "train.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "59개의 변수와 595.212개의 행이 있다. 테스트 데이터에 같은 수의 변수가 있는지 보자.\n",
    "훈련 데이터에 중복 행이 있는지도 살펴보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T09:49:15.370213Z",
     "iopub.status.busy": "2022-02-13T09:49:15.369302Z",
     "iopub.status.idle": "2022-02-13T09:49:16.340019Z",
     "shell.execute_reply": "2022-02-13T09:49:16.339169Z",
     "shell.execute_reply.started": "2022-02-13T09:49:15.370179Z"
    }
   },
   "outputs": [],
   "source": [
    "train.drop_duplicates()\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "중복 행이 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T09:49:16.341997Z",
     "iopub.status.busy": "2022-02-13T09:49:16.341692Z",
     "iopub.status.idle": "2022-02-13T09:49:16.348765Z",
     "shell.execute_reply": "2022-02-13T09:49:16.347556Z",
     "shell.execute_reply.started": "2022-02-13T09:49:16.341956Z"
    }
   },
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "테스트 세트에서 하나의 변수(컬럼)가 누락되었지만 이것이 타겟 변수라서 괜찮다.\n",
    "이제 각 유형의 변수가 몇 개인지 조사해 보자.\n",
    "\n",
    "따라서 나중에 14개의 범주형 변수에 대한 더미 변수를 만들 수 있다. bin 변수는 이미 바이너리이며 더미화가 필요하지 않다.(바이너리: 0,1로 나타나져있어서 더미화로 나눌 필요 없음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T09:49:16.350561Z",
     "iopub.status.busy": "2022-02-13T09:49:16.350303Z",
     "iopub.status.idle": "2022-02-13T09:49:16.437757Z",
     "shell.execute_reply": "2022-02-13T09:49:16.436732Z",
     "shell.execute_reply.started": "2022-02-13T09:49:16.350532Z"
    }
   },
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터들의 타입이 정수형이거나 소수형이다.\n",
    "- 결측값이 -1로 되어 있어 결측값이 없는 것으로 확인되는데 이것은 후에 다룰 것.\n",
    "\n",
    "### Metadata\n",
    "\n",
    ":[데이터에 관한 구조화된 데이터로, 다른 데이터를 설명해 주는 데이터]\n",
    "\n",
    "데이터 관리를 용이하게 하기 위해 variables의 정보들을 DataFrame으로 저장해보자. \n",
    "\n",
    "이렇게 저장한 데이터프레임은, 분석에 필요한 특정한 variables를 선택할 때, 시각화를 할 때, 모델링을 할 때 등에 도움이 될 것이다.\n",
    "\n",
    "구체적으로 저장해야 할 것들은 다음과 같다.\n",
    "\n",
    "- role: input, ID, target\n",
    "- level: nominal, interval, ordinal, binary\n",
    "- keep: True or False\n",
    "- dtype: int, float, str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T09:49:16.439703Z",
     "iopub.status.busy": "2022-02-13T09:49:16.439379Z",
     "iopub.status.idle": "2022-02-13T09:49:16.452983Z",
     "shell.execute_reply": "2022-02-13T09:49:16.452037Z",
     "shell.execute_reply.started": "2022-02-13T09:49:16.43966Z"
    }
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for f in train.columns:\n",
    "    #Defining the role\n",
    "    if f == 'target':\n",
    "        role = 'target'\n",
    "    elif f == 'id':\n",
    "        role = 'id'\n",
    "    else:\n",
    "        role = 'input'\n",
    "        \n",
    "    #Defining the level\n",
    "    if 'bin' in f or f == 'target':\n",
    "        level = 'binary'\n",
    "    elif 'cat' in f or f == 'id':\n",
    "        level = 'nominal'\n",
    "    elif train[f].dtype == float:\n",
    "        level = 'interval'\n",
    "    elif train[f].dtype == int:\n",
    "        level = 'ordinal'\n",
    "        \n",
    "    # Initialize keep to True for all variables except for id\n",
    "    keep = True\n",
    "    if f == 'id':\n",
    "        keep = False\n",
    "        \n",
    "    #Defining the data type\n",
    "    dtype = train[f].dtype\n",
    "    \n",
    "    #Creating a Dict that contains all the metadata for the variable\n",
    "    f_dict = {\n",
    "        'varname' : f,\n",
    "        'role': role,\n",
    "        'level': level,\n",
    "        'keep' : keep,\n",
    "        'dtype': dtype\n",
    "    }\n",
    "    data.append(f_dict)\n",
    "    \n",
    "meta = pd.DataFrame(data, columns = ['varname', 'role', 'level', 'keep', 'dtype'])\n",
    "meta.set_index('varname', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T09:49:16.456543Z",
     "iopub.status.busy": "2022-02-13T09:49:16.455811Z",
     "iopub.status.idle": "2022-02-13T09:49:16.481101Z",
     "shell.execute_reply": "2022-02-13T09:49:16.480059Z",
     "shell.execute_reply.started": "2022-02-13T09:49:16.456499Z"
    }
   },
   "outputs": [],
   "source": [
    "meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예시로 level이 nominal인 데이터의 인덱스를 추출해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T09:49:16.483554Z",
     "iopub.status.busy": "2022-02-13T09:49:16.48276Z",
     "iopub.status.idle": "2022-02-13T09:49:16.500502Z",
     "shell.execute_reply": "2022-02-13T09:49:16.4996Z",
     "shell.execute_reply.started": "2022-02-13T09:49:16.483507Z"
    }
   },
   "outputs": [],
   "source": [
    "meta[(meta.level == 'nominal') & (meta.keep)].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### role과 level에 따른 target의 수를 아래를 통해 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T09:49:16.501899Z",
     "iopub.status.busy": "2022-02-13T09:49:16.501685Z",
     "iopub.status.idle": "2022-02-13T09:49:16.512067Z",
     "shell.execute_reply": "2022-02-13T09:49:16.511016Z",
     "shell.execute_reply.started": "2022-02-13T09:49:16.501874Z"
    }
   },
   "outputs": [],
   "source": [
    "meta[(meta.level == 'nominal')].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T09:49:16.513749Z",
     "iopub.status.busy": "2022-02-13T09:49:16.513351Z",
     "iopub.status.idle": "2022-02-13T09:49:16.531546Z",
     "shell.execute_reply": "2022-02-13T09:49:16.530695Z",
     "shell.execute_reply.started": "2022-02-13T09:49:16.513715Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({'count': meta.groupby(['role', 'level'])['role'].size()}).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ****Descriptive statistics****\n",
    "\n",
    ": 기술 통계(확보한 데이터를 이해하기 쉬운 수치로 요약하는 기법)\n",
    "\n",
    "- 데이터프레임에 describe 메소드를 사용하여 기술통계량을 살펴보도록 하자.\n",
    "- 그러나 describe 메소드는 categorical, id variable의 기술통계량은 계산해주지 않는다.  그러니 추후에 categorical variables를 살펴보도록 하자.\n",
    "\n",
    "메타 데이터를 이용하여 손쉽게 기술통계량을 계산할 수 있다.\n",
    "\n",
    "### ****Interval variables****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T09:49:16.533459Z",
     "iopub.status.busy": "2022-02-13T09:49:16.532791Z",
     "iopub.status.idle": "2022-02-13T09:49:16.825438Z",
     "shell.execute_reply": "2022-02-13T09:49:16.824648Z",
     "shell.execute_reply.started": "2022-02-13T09:49:16.533414Z"
    }
   },
   "outputs": [],
   "source": [
    "v = meta[(meta.level == 'interval') & (meta.keep)].index\n",
    "train[v].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reg variables\n",
    "![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/9f8d4b3f-a8e4-48e8-b87f-4b675f7735ff/Untitled.png)\n",
    "\n",
    "- ps_car_12 및 ps_car_14에 누락된 값이 있다.(min = -1)\n",
    "- 변수에 따라 범위가 다르기 때문에 이 variables 역시, 스케일링이 필요해보인다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### car variables\n",
    "![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/3271c04c-db48-4f91-8cee-bf16d895cee4/Untitled.png)\n",
    "* ps_car_12 및 ps_car_15에 누락된 값이 있다.\n",
    "* 다시, 범위가 다르며 스케일링을 적용할 수 있다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### calc variables\n",
    "![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/66fdd8f5-55a3-45f7-9400-bf969d3b6a92/Untitled.png)\n",
    "- 결측치가 없다.(min = 0)\n",
    "- 이 variables는 최대값이 0.9인것으로 보아 일종의 비율인 것 같다.\n",
    "- 모든 3개의 *_calc* variables은 매우 비슷한 분포를 가지고 있다. & 범위도 같음\n",
    "\n",
    "**전반적으로**, interval variables들 간의 범위가 상대적으로 좁음을 확인 가능하다. (제일 큰 게 -1~4.0)\n",
    "\n",
    "아마도 데이터를 익명화시키기 위하여 몇몇 변환 작업(예를 들어 log)가 이미 적용된 것은 아닐까 생각된다.\n",
    "\n",
    "### 기술통계를 살펴봄으로써 다음과 같은 결과를 얻었다\n",
    "\n",
    "- Feature 내부에 결측치의 존재 유무(-1의 유무)\n",
    "- min과 max를 비교함으로써 스케일링의 필요성 판단(범위 크기 차이)\n",
    "- max 값을 살펴봄으로써 변수의 값이 비율인지 판단(calc)\n",
    "\n",
    "### Ordinal variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T09:49:16.82697Z",
     "iopub.status.busy": "2022-02-13T09:49:16.826739Z",
     "iopub.status.idle": "2022-02-13T09:49:17.191886Z",
     "shell.execute_reply": "2022-02-13T09:49:17.190895Z",
     "shell.execute_reply.started": "2022-02-13T09:49:16.826941Z"
    }
   },
   "outputs": [],
   "source": [
    "v = meta[(meta.level == 'ordinal') & (meta.keep)].index\n",
    "train[v].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 하나의 누락된 변수: ps_car_11\n",
    "* 다양한 범위를 처리하기 위해 스케일링을 적용할 수 있습니다.\n",
    "\n",
    "### Binary variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T09:49:17.193944Z",
     "iopub.status.busy": "2022-02-13T09:49:17.193625Z",
     "iopub.status.idle": "2022-02-13T09:49:17.528311Z",
     "shell.execute_reply": "2022-02-13T09:49:17.527328Z",
     "shell.execute_reply.started": "2022-02-13T09:49:17.193905Z"
    }
   },
   "outputs": [],
   "source": [
    "v = meta[(meta.level == 'binary') & (meta.keep)].index\n",
    "train[v].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train 데이터의 target 평균은 0.036448로 3.645% 인데, 결과값이 매우 불균형함을 알 수 있다.\n",
    "![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/20ea0200-888a-453f-b10a-eafb85a8dce9/Untitled.png)\n",
    "평균값을 통해 대다수의 variables가 0이라고 결론내릴 수 있다.\n",
    "\n",
    "\n",
    "## Handling imbalanced classes\n",
    "\n",
    "위에서 언급했듯이 target=1인 레코드의 비율은 target=0보다 훨씬 적다. 이것은 정확도가 높지만 실제로는 부가 가치가 있는 모델로 이어질 수 있다. 이 문제를 처리하기 위한 두 가지 가능한 전략은 다음과 같다.\n",
    "\n",
    "* target=1인 오버샘플링 레코드\n",
    "* target=0인 언더샘플링 레코드\n",
    "\n",
    "물론 더 많은 전략이 있으며 MachineLearningMastery.com은 좋은 개요를 제공한다. 우리는 훈련 세트가 상당히 크기 때문에 언더샘플링을 할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T09:49:17.530407Z",
     "iopub.status.busy": "2022-02-13T09:49:17.52979Z",
     "iopub.status.idle": "2022-02-13T09:49:18.100327Z",
     "shell.execute_reply": "2022-02-13T09:49:18.099382Z",
     "shell.execute_reply.started": "2022-02-13T09:49:17.530364Z"
    }
   },
   "outputs": [],
   "source": [
    "desired_apriori = 0.10\n",
    "\n",
    "#get the indices per target value\n",
    "idx_0 = train[train.target == 0].index\n",
    "idx_1 = train[train.target == 1].index\n",
    "\n",
    "#get original number of records per target value\n",
    "nb_0 = len(train.loc[idx_0])\n",
    "nb_1 = len(train.loc[idx_1])\n",
    "\n",
    "#Calculate the undersampling rate and resulting number of records with target = 0\n",
    "undersampling_rate = ((1-desired_apriori)*nb_1)/(nb_0*desired_apriori)\n",
    "undersampled_nb_0 = int(undersampling_rate*nb_0)\n",
    "print('Rate to undersample records with target = 0: {}'.format(undersampling_rate))\n",
    "print('Number of records with target = 0 after undersampling: {}'.format(undersampled_nb_0))\n",
    "\n",
    "#Randomly select records with target = 0 to get at the desired a priori\n",
    "undersampled_idx = shuffle(idx_0, random_state = 37, n_samples = undersampled_nb_0)\n",
    "\n",
    "#Construct list with remaining indeices\n",
    "idx_list = list(undersampled_idx) + list(idx_1)\n",
    "\n",
    "#Return undersample data frame\n",
    "train = train.loc[idx_list].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Quality Checks\n",
    "## Checking missing values\n",
    "\n",
    "누락은 -1로 표시된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T09:49:18.101913Z",
     "iopub.status.busy": "2022-02-13T09:49:18.101602Z",
     "iopub.status.idle": "2022-02-13T09:49:18.238021Z",
     "shell.execute_reply": "2022-02-13T09:49:18.237124Z",
     "shell.execute_reply.started": "2022-02-13T09:49:18.101882Z"
    }
   },
   "outputs": [],
   "source": [
    "vars_with_missing = []\n",
    "\n",
    "for f in train.columns:\n",
    "    missings = train[train[f] == -1][f].count()\n",
    "    if missings > 0:\n",
    "        vars_with_missing.append(f)\n",
    "        missings_perc = missings/train.shape[0]\n",
    "        \n",
    "        print('Variable {} has {} records ({:.2%}) with missing values'.format(f, missings, missings_perc))\n",
    "        \n",
    "print('In total, there are {} variables with missing values'.format(len(vars_with_missing)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ps_car_03_cat 및 ps_car_05_cat에는 결측값이 있는 레코드의 비율이 높다. 이러한 변수를 제거하자.\n",
    "* 결측값이 있는 다른 범주형 변수의 경우 결측값 -1을 그대로 둘 수 있다.\n",
    "* ps_reg_03(연속)에 모든 레코드의 18%에 대한 결측값이 있다. 평균으로 교체하자.\n",
    "* ps_car_11(서수)에는 값이 누락된 레코드가 5개뿐이다. 모드로 교체하자.\n",
    "* ps_car_12(연속)에는 누락된 값이 있는 레코드가 1개뿐이다. 평균으로 교체하자.\n",
    "* ps_car_14(연속)에 모든 레코드의 7%에 대한 결측값이 있다. 평균으로 교체하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T09:49:18.239728Z",
     "iopub.status.busy": "2022-02-13T09:49:18.239433Z",
     "iopub.status.idle": "2022-02-13T09:49:18.243833Z",
     "shell.execute_reply": "2022-02-13T09:49:18.242985Z",
     "shell.execute_reply.started": "2022-02-13T09:49:18.239688Z"
    }
   },
   "outputs": [],
   "source": [
    "#Imputer =SimpleImputer(missing_values=np.nan, strategy='mean')#Imputing with the mean or mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T09:49:18.245006Z",
     "iopub.status.busy": "2022-02-13T09:49:18.244807Z",
     "iopub.status.idle": "2022-02-13T09:49:18.289064Z",
     "shell.execute_reply": "2022-02-13T09:49:18.288098Z",
     "shell.execute_reply.started": "2022-02-13T09:49:18.244982Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dropping the variables with too many missing values\n",
    "vars_to_drop = ['ps_car_03_cat', 'ps_car_05_cat']\n",
    "train.drop(vars_to_drop, inplace = True, axis =1)\n",
    "meta.loc[(vars_to_drop), 'keep'] = False #Updating the meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T09:49:18.290717Z",
     "iopub.status.busy": "2022-02-13T09:49:18.290487Z",
     "iopub.status.idle": "2022-02-13T09:49:18.344833Z",
     "shell.execute_reply": "2022-02-13T09:49:18.34389Z",
     "shell.execute_reply.started": "2022-02-13T09:49:18.290691Z"
    }
   },
   "outputs": [],
   "source": [
    "mean_imp = SimpleImputer(missing_values = -1, strategy = 'mean')\n",
    "mode_imp = SimpleImputer(missing_values = -1, strategy = 'most_frequent')\n",
    "train['ps_reg_03'] = mean_imp.fit_transform(train[['ps_reg_03']]).ravel()\n",
    "train['ps_car_12'] = mean_imp.fit_transform(train[['ps_car_12']]).ravel()\n",
    "train['ps_car_14'] = mean_imp.fit_transform(train[['ps_car_14']]).ravel()\n",
    "train['ps_car_11'] = mode_imp.fit_transform(train[['ps_car_11']]).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-10T13:23:55.390098Z",
     "iopub.status.busy": "2022-02-10T13:23:55.388932Z",
     "iopub.status.idle": "2022-02-10T13:23:55.400871Z",
     "shell.execute_reply": "2022-02-10T13:23:55.399634Z",
     "shell.execute_reply.started": "2022-02-10T13:23:55.390045Z"
    }
   },
   "source": [
    "## Checking the cardinality of the categorical variables\n",
    "\n",
    "카디날리티는 전체 행에 대한 특정 컬럼의 중복 수치를 나타내는 지표입니다.\n",
    "중복도가 높으면 카디날리티가 낮으며, 중복도가 낮으면 카디날리티가 높습니다.\n",
    "카디날리티는 상대적인 개념으로 이해해야 합니다.\n",
    "\n",
    "따라서 카디날리티는 variable 내에서 다른 value의 개수를 말합니다. 우리는 추후 categorical variables를 더미화시킬 것인데, variables 내에 다른 value들이 얼마나 많은지 체크해봐야 합니다.Value들이 많을 경우, 수 많은 더미 변수들이 만들어질 수 있기 때문입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T09:49:18.346639Z",
     "iopub.status.busy": "2022-02-13T09:49:18.346338Z",
     "iopub.status.idle": "2022-02-13T09:49:18.376113Z",
     "shell.execute_reply": "2022-02-13T09:49:18.375541Z",
     "shell.execute_reply.started": "2022-02-13T09:49:18.346611Z"
    }
   },
   "outputs": [],
   "source": [
    "v = meta[(meta.level == 'nominal') & (meta.keep)].index\n",
    "\n",
    "for f in v:\n",
    "    dist_values = train[f].value_counts().shape[0]\n",
    "    print('Variabel {} has {} distinct values'.format(f, dist_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "합리적이긴 하지만, ps_car_11_cat는 104개로 매우 많은 Value를 가지고 있습니다.\n",
    "\n",
    "EDIT : 최초 작성자분은 104개의 Value에 대해 가공을 하여 데이터 손실이 있었던 것으로 보입니다. 이후 최초 작성자분은 Oliver의 커널을 활용한 방법을 사용했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T09:49:18.377794Z",
     "iopub.status.busy": "2022-02-13T09:49:18.377316Z",
     "iopub.status.idle": "2022-02-13T09:49:18.392139Z",
     "shell.execute_reply": "2022-02-13T09:49:18.391208Z",
     "shell.execute_reply.started": "2022-02-13T09:49:18.37776Z"
    }
   },
   "outputs": [],
   "source": [
    "# Script by https://www.kaggle.com/ogrellier\n",
    "# Code: https://www.kaggle.com/ogrellier/python-target-encoding-for-categorical-features\n",
    "def add_noise(series, noise_level):\n",
    "    return series * ( 1 + noise_level * np.random.randn(len(series)))\n",
    "\n",
    "def target_encode(trn_series = None,\n",
    "                 tst_series = None,\n",
    "                 target = None,\n",
    "                 min_samples_leaf = 1,\n",
    "                 smoothing = 1,\n",
    "                 noise_level = 0):\n",
    "    '''\n",
    "    Smoothing is computed like in the following paper by Dniele Micci-Barreca\n",
    "    https://kaggle2.blob.core.windows.net/forum-message-attachments/225952/7441/high%20cardinality%20categoricals.pdf\n",
    "    trn_series : training categorical feature as a pd.Series\n",
    "    tst_series : test categorical feature as a pd.Series\n",
    "    target : target data as a pd.Series\n",
    "    min_samples_leaf (int) : minimum samples to take category average into account\n",
    "    smoothing (int) : smoothing effect to balance categorical average vs prior\n",
    "    '''\n",
    "    assert len(trn_series) == len(target)\n",
    "    assert trn_series.name == tst_series.name\n",
    "    temp = pd.concat([trn_series, target], axis =1)\n",
    "    # Conpute target mean\n",
    "    averages = temp.groupby(by = trn_series.name)[target.name].agg(['mean', 'count'])\n",
    "    #compute smoothing\n",
    "    smoothing = 1 / (1 + np.exp(-(averages['count'] - min_samples_leaf) / smoothing))\n",
    "    #Apply average function to all target data\n",
    "    prior = target.mean()\n",
    "    #The bigger the count the less full_avg is taken into account\n",
    "    averages[target.name] = prior * (1-smoothing) + averages['mean'] * smoothing\n",
    "    averages.drop(['mean', 'count'], axis = 1, inplace = True)\n",
    "    #Apply averages to trn and tst series\n",
    "    ft_trn_series = pd.merge(\n",
    "        trn_series.to_frame(trn_series.name),\n",
    "    averages.reset_index().rename(columns = {'index' : target.name, target.name: 'average'}),\n",
    "    on = trn_series.name,\n",
    "    how = 'left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    #pd.merge does not keep the index so restore it\n",
    "    ft_trn_series.index = trn_series.index\n",
    "    ft_tst_series = pd.merge(\n",
    "        tst_series.to_frame(tst_series.name),\n",
    "        averages.reset_index().rename(columns = {'index' : target.name, target.name: 'average'}),\n",
    "        on = tst_series.name,\n",
    "        how = 'left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    #pd.merge does not keep the index so restore it\n",
    "    ft_tst_series.index = tst_series.index\n",
    "    return add_noise(ft_trn_series, noise_level), add_noise(ft_tst_series, noise_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T09:49:18.393999Z",
     "iopub.status.busy": "2022-02-13T09:49:18.393425Z",
     "iopub.status.idle": "2022-02-13T09:49:18.820501Z",
     "shell.execute_reply": "2022-02-13T09:49:18.819733Z",
     "shell.execute_reply.started": "2022-02-13T09:49:18.39393Z"
    }
   },
   "outputs": [],
   "source": [
    "train_encoded, test_encoded = target_encode(train['ps_car_11_cat'],\n",
    "                                           test['ps_car_11_cat'],\n",
    "                                           target = train.target,\n",
    "                                           min_samples_leaf = 100,\n",
    "                                           smoothing = 10,\n",
    "                                           noise_level = 0.01)\n",
    "\n",
    "train['ps_car_11_cat_te'] = train_encoded\n",
    "train.drop('ps_car_11_cat', axis = 1, inplace=True)\n",
    "meta.loc['ps_car_11_cat','keep'] = False  #Updating the meta\n",
    "test['ps_car_11_cat_te'] = test_encoded\n",
    "test.drop('ps_car_11_cat', axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Visualization 데이터 시각화\n",
    "\n",
    "target 값이 1인 categorical variables와 customers의 비율을 살펴보도록 합시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T09:49:18.822445Z",
     "iopub.status.busy": "2022-02-13T09:49:18.821648Z",
     "iopub.status.idle": "2022-02-13T09:49:21.63086Z",
     "shell.execute_reply": "2022-02-13T09:49:21.629964Z",
     "shell.execute_reply.started": "2022-02-13T09:49:18.822412Z"
    }
   },
   "outputs": [],
   "source": [
    "v = meta[(meta.level == 'nominal') & (meta.keep)].index\n",
    "\n",
    "for f in v:\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots(figsize = (20, 10))\n",
    "    #Calculate the percentage of target = 1 per category value\n",
    "    cat_perc = train[[f, 'target']].groupby([f], as_index = False).mean()\n",
    "    cat_perc.sort_values(by='target', ascending = False, inplace = True)\n",
    "    # Bar plot\n",
    "    # Order the bars descending on target mean\n",
    "    sns.barplot(ax= ax, x = f, y= 'target', data =cat_perc, order = cat_perc[f])\n",
    "    plt.xlabel(f, fontsize =18)\n",
    "    plt.ylabel('% target', fontsize = 18)\n",
    "    plt.tick_params(axis = 'both', which = 'major', labelsize = 18)\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "막대 그래프들을 통해 결측값이 있는 variables들을 확인할 수 있습니다. 앞서 결측값들을 치환했는데, categorical variables들은 따로 치환을 하지 않았습니다. 최빈값으로 대체하는 것보다 분리된 category value로서 결측값을 보는 것이 더 좋은 방법일 수 있습니다.\n",
    "\n",
    "결측값을 가지고 있는 Customer들이 다른 Value들에 비하여 훨씬 높은 target 평균을 가지고 있기 때문입니다!\n",
    "\n",
    "## Interval variables\n",
    "\n",
    "interval variables의 상관관계를 확인하고자 합니다. Heatmap은 Variables 간의 상관관계를 확인하는데 매우 효율적입니다. 하기 코드는 an example by Michael Waskom에 기반하고 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T09:49:21.632129Z",
     "iopub.status.busy": "2022-02-13T09:49:21.631922Z",
     "iopub.status.idle": "2022-02-13T09:49:22.410282Z",
     "shell.execute_reply": "2022-02-13T09:49:22.409288Z",
     "shell.execute_reply.started": "2022-02-13T09:49:21.632104Z"
    }
   },
   "outputs": [],
   "source": [
    "def corr_heatmap(v):\n",
    "    correlations = train[v].corr()\n",
    "    \n",
    "    # Create color map ranging between two colors\n",
    "    cmap = sns.diverging_palette(220, 10, as_cmap = True)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize = (10, 10))\n",
    "    sns.heatmap(correlations, cmap=cmap, vmax = 1.0, center = 0, fmt = '.2f',\n",
    "               square = True, linewidths = .5, annot = True, cbar_kws = {'shrink': .75})\n",
    "    plt.show();\n",
    "    \n",
    "v = meta[(meta.level == 'interval') & (meta.keep)].index\n",
    "corr_heatmap(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "강한 상관관계를 가지고 있는 Variables들은 다음과 같습니다. :\n",
    "\n",
    "* ps_reg_02 and ps_reg_03 (0.7)\n",
    "* ps_car_12 and ps_car13 (0.67)\n",
    "* ps_car_12 and ps_car14 (0.58)\n",
    "* ps_car_13 and ps_car15 (0.67)\n",
    "\n",
    "Seaborn의 pair plot을 사용하면 variables들의 (선형) 관계를 손쉽게 시각화할 수 있습니다. 하지만 히트맵이 상관관계가 있는 variables들의 관계들을 시각화해주고 있기 때문에, 우리는 높은 상관관계를 보이는 variables들을 분리해서 보고자 합니다.\n",
    "\n",
    "Note 프로세스의 속도를 높이기 위하여 train 데이터의 sample을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T09:49:22.411613Z",
     "iopub.status.busy": "2022-02-13T09:49:22.411397Z",
     "iopub.status.idle": "2022-02-13T09:49:22.438107Z",
     "shell.execute_reply": "2022-02-13T09:49:22.437405Z",
     "shell.execute_reply.started": "2022-02-13T09:49:22.411587Z"
    }
   },
   "outputs": [],
   "source": [
    "s = train.sample(frac = 0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train 데이터에서 10%의 데이터를 샘플링합니다.\n",
    "\n",
    "* train.shape ▶ (216940, 57)\n",
    "* s.shape ▶ (21694, 57)\n",
    "\n",
    "### ps_reg_02 and ps_reg_03 (0.7)\n",
    "회귀선이 보여주듯이, 두 variables들 간에는 선형 상관관계를 살펴볼 수 있습니다. hue 파라미터를 통해 target=0과 target=1에 대한 회귀선이 동일함을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T09:49:22.442016Z",
     "iopub.status.busy": "2022-02-13T09:49:22.44133Z",
     "iopub.status.idle": "2022-02-13T09:49:24.36688Z",
     "shell.execute_reply": "2022-02-13T09:49:24.366108Z",
     "shell.execute_reply.started": "2022-02-13T09:49:22.441983Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.lmplot(x = 'ps_reg_02', y='ps_reg_03', data=s, hue = 'target', palette = 'Set1', scatter_kws = {'alpha':0.3})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ps_car_12 and ps_car_13 (0.67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T09:49:24.368393Z",
     "iopub.status.busy": "2022-02-13T09:49:24.368049Z",
     "iopub.status.idle": "2022-02-13T09:49:26.270561Z",
     "shell.execute_reply": "2022-02-13T09:49:26.269896Z",
     "shell.execute_reply.started": "2022-02-13T09:49:24.368364Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.lmplot(x = 'ps_car_12', y = 'ps_car_13', data =s, hue = 'target', palette = 'Set1', scatter_kws = {'alpha': 0.3})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ps_car_12 and ps_car_14 (0.58)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T09:49:26.272143Z",
     "iopub.status.busy": "2022-02-13T09:49:26.271669Z",
     "iopub.status.idle": "2022-02-13T09:49:28.128517Z",
     "shell.execute_reply": "2022-02-13T09:49:28.127698Z",
     "shell.execute_reply.started": "2022-02-13T09:49:26.272108Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.lmplot(x = 'ps_car_12', y = 'ps_car_14', data = s, hue='target', palette = 'Set1', scatter_kws = {'alpha':0.3})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ps_car_13 and ps_car_15 (0.67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T09:49:28.130265Z",
     "iopub.status.busy": "2022-02-13T09:49:28.130039Z",
     "iopub.status.idle": "2022-02-13T09:49:30.01716Z",
     "shell.execute_reply": "2022-02-13T09:49:30.016284Z",
     "shell.execute_reply.started": "2022-02-13T09:49:28.130222Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.lmplot(x = 'ps_car_15', y = 'ps_car_13', data = s, hue = 'target', palette = 'Set1', scatter_kws = {'alpha':0.3})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제는 어떤 correlated variables를 유지할지 결정해야 합니다. 이를 위하여 우리는 Principal Component Analysis (PCA), 주성분 분석을 실시하여 variables의 dimensions를 줄일 수 있습니다. 하지만 correlated variables의 수가 적은만큼, 우리는 모델이 heavy-lifting을 하도록 해야합니다.\n",
    "\n",
    "## Checking the correlations between ordinal variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T09:49:30.018506Z",
     "iopub.status.busy": "2022-02-13T09:49:30.018289Z",
     "iopub.status.idle": "2022-02-13T09:49:31.599928Z",
     "shell.execute_reply": "2022-02-13T09:49:31.599066Z",
     "shell.execute_reply.started": "2022-02-13T09:49:30.018479Z"
    }
   },
   "outputs": [],
   "source": [
    "v = meta[(meta.level == 'ordinal') & (meta.keep)].index\n",
    "corr_heatmap(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ordinal variables는 큰 상관관계를 가지고 있지 않은 것으로 보입니다. 반면에 target 값으로 그룹화할 때 분포가 어떻게 될지 확인할 수 있습니다.\n",
    "\n",
    "# Feature engineering\n",
    "\n",
    "## Creating dummy variables\n",
    "\n",
    "categorical variables는 어떤 순서나 경중이 담겨있지 않습니다. 예를 들어서 카테고리 2는 카테고리 1보다 2배의 값을 가지고 있지 않습니다. 이 문제는 더미 데이터를 만들어줌으로써 해결할 수 있습니다. 첫 번째 dummy variable의 정보는 원래 variables의 범주에 대해 생성된 다른 dummy variable에서 파생될 수 있으므로 삭제해주도록 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T09:49:31.602081Z",
     "iopub.status.busy": "2022-02-13T09:49:31.601403Z",
     "iopub.status.idle": "2022-02-13T09:49:31.811323Z",
     "shell.execute_reply": "2022-02-13T09:49:31.810471Z",
     "shell.execute_reply.started": "2022-02-13T09:49:31.602044Z"
    }
   },
   "outputs": [],
   "source": [
    "v = meta[(meta.level == 'nominal') & (meta.keep)].index\n",
    "print('before dummification we have {} variables in train'.format(train.shape[1]))\n",
    "train = pd.get_dummies(train, columns = v, drop_first = True)\n",
    "print('After dummification we have {} variables in train'.format(train.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dummy variables는 training 데이터 세트에 52개의 variables를 추가했습니다.\n",
    "\n",
    "## Creating interaction variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T09:49:31.81359Z",
     "iopub.status.busy": "2022-02-13T09:49:31.812905Z",
     "iopub.status.idle": "2022-02-13T09:49:32.221791Z",
     "shell.execute_reply": "2022-02-13T09:49:32.220061Z",
     "shell.execute_reply.started": "2022-02-13T09:49:31.813542Z"
    }
   },
   "outputs": [],
   "source": [
    "v = meta[(meta.level == 'interval') & (meta.keep)].index\n",
    "poly = PolynomialFeatures(degree = 2, interaction_only = False, include_bias = False)\n",
    "interactions = pd.DataFrame(data = poly.fit_transform(train[v]), columns = poly.get_feature_names(v))\n",
    "interactions.drop(v, axis = 1, inplace = True) #poly 처리가 되지 않은 기존의 열들을 삭제한다.\n",
    "\n",
    "#interactions와 train 데이터를 합쳐준다\n",
    "print('Before crating interactions we have {} variabbles in train'.format(train.shape[1]))\n",
    "train = pd.concat([train, interactions], axis = 1)\n",
    "print('After creating interactions we have {} variables in train'.format(train.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PolynomialFeatures는 다항차수 변환을 진행을 도와주는 클래스입니다. 상기 코드의 경우 degree를 2로 설정했으니 2차항 변수로 만들어주는 것입니다.\n",
    "\n",
    "이를 통해 train 데이터에 interaction variables를 추가할 수 있습니다. get_feature_names 메소드 덕분에 열 이름을 할당할 수 있습니다.\n",
    "\n",
    "# Feature selection\n",
    "\n",
    "## Removing features with low or zero variance\n",
    "\n",
    "개인적으로 작성자는 분류기의 알고리즘이 유지할 features를 선택하는 것을 선호한다고 합니다. 하지만 우리 스스로 할 수 있는 일도 있습니다. 분산이 0이거나 아주 적은 features들을 제거하는 것입니다.\n",
    "\n",
    "\n",
    "이를 위해 사이킷런의 VarianceThreshold라는 메소드를 사용할 수 있습니다. 기본적으로 이 메소드는 분산 값이 0인 features들을 제거해줍니다.\n",
    "\n",
    "\n",
    "하지만 저희는 이전 단계에서 이미 분산이 0인 features가 없음을 확인했기 때문에, 우리는 1% 미만의 분산이 있는 features들을 제거해주고자 합니다. 이를 통해 우리는 31개의 variables를 제거하게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T09:49:32.22356Z",
     "iopub.status.busy": "2022-02-13T09:49:32.223226Z",
     "iopub.status.idle": "2022-02-13T09:49:32.890455Z",
     "shell.execute_reply": "2022-02-13T09:49:32.889543Z",
     "shell.execute_reply.started": "2022-02-13T09:49:32.22352Z"
    }
   },
   "outputs": [],
   "source": [
    "selector = VarianceThreshold(threshold = .01)\n",
    "selector.fit(train.drop(['id', 'target'], axis = 1)) # Fit to train without id and target variables\n",
    "\n",
    "f = np.vectorize(lambda x: not x) #Function to toggle boolean array elements\n",
    "\n",
    "v = train.drop(['id', 'target'], axis = 1).columns[f(selector.get_support())]\n",
    "print('{} variables have too low variance.'.format(len(v)))\n",
    "print('these variables are {}'.format(list(v)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만약 우리가 분산에 기반하여 선택을 진행한다면 많은 variables들을 잃게 될 것입니다. 하지만 우리는 많은 variables를 가지고 있지 않기 때문에, 분류기가 직접 선택하도록 합니다. variables가 더 많은 데이터 셋이라면 처리 시간을 줄여줄 수 있을 것입니다.\n",
    "\n",
    "사이킷런은 [feature selecetion methods]를 제공합니다. 이 메소드 중 하나가 'SelectFromModel' 인데, 다른 분류기에서 최상의 feature를 선택하고 기능을 계속할 수 있도록 합니다. 아래를 통해 랜덤 포레스트를 어떻게 사용하는지 확인해보도록 합니다.\n",
    "\n",
    "# Selecting features with a Random Forest and SelectFromModel\n",
    "\n",
    "우리는 랜덤 포레스트의 feature importances에 따라 feature 선택의 기준을 삼습니다. SelectFromModel을 통하여 유지할 variables의 숫자를 구체화할 수 있습니다. feature의 중요도에 대한 임곗값을 수동으로 설정할수 있지만, 우리는 단순히 50% 이상의 최적의 variables를 선택해보도록 합시다.\n",
    "\n",
    ">하기의 코드는 이곳에서 가져왔습니다. GitHub repo of Sebastian Raschka.(https://github.com/rasbt/python-machine-learning-book/blob/master/code/ch04/ch04.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T09:49:32.89176Z",
     "iopub.status.busy": "2022-02-13T09:49:32.891553Z",
     "iopub.status.idle": "2022-02-13T10:00:41.675635Z",
     "shell.execute_reply": "2022-02-13T10:00:41.674074Z",
     "shell.execute_reply.started": "2022-02-13T09:49:32.891735Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = train.drop(['id', 'target'], axis=1)\n",
    "y_train = train['target']\n",
    "\n",
    "feat_labels = X_train.columns\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=1000, random_state=0, n_jobs=-1)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "indices = np.argsort(rf.feature_importances_)[::-1]\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f + 1, 30,feat_labels[indices[f]], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SelectFromModel을 사용하면 사용할 사전 적합 분류기와 기능 중요도에 대한 임계값을 지정할 수 있습니다. get_support 메소드를 사용하여 기차 데이터의 변수 수를 제한할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T10:00:41.678491Z",
     "iopub.status.busy": "2022-02-13T10:00:41.678179Z",
     "iopub.status.idle": "2022-02-13T10:00:42.710633Z",
     "shell.execute_reply": "2022-02-13T10:00:42.709613Z",
     "shell.execute_reply.started": "2022-02-13T10:00:41.678455Z"
    }
   },
   "outputs": [],
   "source": [
    "sfm = SelectFromModel(rf, threshold = 'median', prefit = True)\n",
    "print('Number of features before selection: {}'.format(X_train.shape[1]))\n",
    "n_features = sfm.transform(X_train).shape[1]\n",
    "print('Number of features after selection: {}'.format(n_features))\n",
    "selected_vars = list(feat_labels[sfm.get_support()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T10:00:42.712786Z",
     "iopub.status.busy": "2022-02-13T10:00:42.712484Z",
     "iopub.status.idle": "2022-02-13T10:00:42.773812Z",
     "shell.execute_reply": "2022-02-13T10:00:42.772761Z",
     "shell.execute_reply.started": "2022-02-13T10:00:42.712747Z"
    }
   },
   "outputs": [],
   "source": [
    "train = train[selected_vars + ['target']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature scaling\n",
    "이전에 언급했듯이, 우리는 train 데이터에 정규화를 진행할 수 있습니다. 몇몇 분류기에서는 더 나은 결과를 가져올 수 있을 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T10:00:42.775742Z",
     "iopub.status.busy": "2022-02-13T10:00:42.775426Z",
     "iopub.status.idle": "2022-02-13T10:00:43.328322Z",
     "shell.execute_reply": "2022-02-13T10:00:43.327445Z",
     "shell.execute_reply.started": "2022-02-13T10:00:42.775702Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(train.drop(['target'], axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우왕 끝!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
